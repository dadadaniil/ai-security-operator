services:
  db:
    image: postgres:13-alpine
    environment:
      POSTGRES_USER: msf
      POSTGRES_PASSWORD: msf
      POSTGRES_DB: msf
    volumes:
      - msf-db:/var/lib/postgresql/data
    restart: unless-stopped
    ports:
      - "5433:5432"
    networks:
      - msf-network

  metasploit:
    image: metasploitframework/metasploit-framework:latest
    depends_on:
      - db
    environment:
      DATABASE_URL: postgres://msf:msf@db:5432/msf
      POSTGRES_HOST: db
      POSTGRES_USER: msf
      POSTGRES_PASSWORD: msf
      POSTGRES_DB: msf
    ports:
      - "55553:55553"
    entrypoint: ["./msfconsole", "-q", "-x", "load msgrpc ServerHost=0.0.0.0 ServerPort=55553 User=msf Pass=msf SSL=false"]
    working_dir: /usr/src/metasploit-framework
    stdin_open: true
    tty: true
    volumes:
      - msf-data:/home/msf/.msf4
    restart: unless-stopped
    networks:
      - msf-network

  exploiter:
    build: ./exploiter
    depends_on:
      - metasploit
    environment:
      - MSF_HOST=metasploit
      - MSF_PORT=55553
      - MSF_USER=msf
      - MSF_PASS=msf
      - TARGET_HOST=backend
      - PORT=8081
      - LOG_LEVEL=INFO
    ports:
      - "8081:8081"
    restart: on-failure
    networks:
      - msf-network
      - application_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  github-bot:
    build: ./github-bot
    env_file:
      - ./github-bot.env
    environment:
      - ANALYZER_BASEURL=http://analyzer:8000/
      - PORT=3000
    ports:
      - "3000:3000"
    networks:
      - msf-network
    restart: on-failure

  smee-client:
    image: node:18-alpine
    restart: unless-stopped
    command: >
      sh -c "npm install --global smee-client && 
             smee -u https://smee.io/MQFI8eHvKVJBzDD8 -t http://github-bot:3000/webhook"
    networks:
      - msf-network
    depends_on:
      - github-bot

  ollama:
    pull_policy: always
    build:
      context: .
      dockerfile: ollama.Dockerfile
    volumes:
      - type: bind
        source: /ollama-entrypoint.sh
        target: /root/.ollama
    networks:
      - msf-network
    ports:
      - "11434:11434"
    restart: always
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]

  analyzer:
    image: ${DOCKER_REGISTRY-}ai-analyzer
    depends_on:
      - ollama
    ports:
      - "8000:8000/tcp"
    build:
      context: .
      dockerfile: analyzer/ai-analyzer.Dockerfile
    networks:
      - msf-network
    environment:
      - API_PORT=8000
      - LLM_MODEL=llama3.2
      - VECTORSTORE_PATH=./chroma_db
      - LLM_OUTPUT_TOKEN_LIMIT=120
      - OLLAMA_HOST=http://ollama:11434/

networks:
  msf-network:
    driver: bridge
  application_network:
    external: true

volumes:
  msf-db:
  msf-data:
  ollama: {}
