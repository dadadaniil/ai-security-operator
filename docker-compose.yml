services:

  github-bot:
    build: ./github-bot
    env_file:
      - ./github-bot.env
    environment:
      - PORT=3000
    ports:
      - "3000:3000"
    networks:
      - msf-network
    restart: on-failure

  smee-client:
    image: node:18-alpine
    restart: unless-stopped 
    command: >
      sh -c "npm install --global smee-client && 
             smee -u https://smee.io/MQFI8eHvKVJBzDD8 -t http://github-bot:3000/webhook"
    networks:
      - msf-network
    depends_on:
      - github-bot

  ollama:
    pull_policy: always
    build:
      context: .
      dockerfile: ollama.Dockerfile
    volumes:
      - type: bind
        source: /ollama-entrypoint.sh
        target: /root/.ollama
    ports:
      - "11434:11434"
    restart: always

  analyzer:
    image: ${DOCKER_REGISTRY-}ai-analyzer
    depends_on:
      - ollama
    ports:
      - "8000:8000/tcp"
    build:
      context: .
      dockerfile: analyzer/ai-analyzer.Dockerfile
    environment:
      - API_PORT=8000
      - LLM_MODEL=llama3.2
      - VECTORSTORE_PATH=./chroma_db
      - LLM_OUTPUT_TOKEN_LIMIT=120
      - OLLAMA_HOST=http://ollama:11434/

networks:
  msf-network:
    driver: bridge

volumes:
  ollama: {}
